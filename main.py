import gradio as gr
import cv2
import numpy as np
import tempfile

def track_video(video_path, algorithm_type):
    cap = cv2.VideoCapture(video_path)
    ret, first_frame = cap.read()

    if not ret:
        return None

    # æ‰“å¼€æ‰“æ ‡çª—å£
    # ç¼©å°æ˜¾ç¤ºæ¯”ä¾‹
    scale = 0.5
    resized = cv2.resize(first_frame, None, fx=scale, fy=scale)

    # åœ¨ç¼©å°å›¾ä¸Šæ‰“æ ‡
    roi_resized = cv2.selectROI("åœ¨ç¬¬ä¸€å¸§é€‰æ‹©è¿½è¸ªç›®æ ‡ï¼ˆæŒ‰ Enter ç¡®è®¤ï¼‰", resized, fromCenter=False)
    cv2.destroyAllWindows()

    # å°† ROI æ˜ å°„å›åŸå§‹å°ºå¯¸
    x, y, w, h = roi_resized
    roi = (int(x / scale), int(y / scale), int(w / scale), int(h / scale))

    height, width = first_frame.shape[:2]
    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps == 0 or fps is None or fps < 1:
        fps = 30  # é»˜è®¤30fps

    output_path = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False).name
    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))

    if algorithm_type == "CSRTè¿½è¸ªå™¨":
        tracker = cv2.TrackerCSRT_create()
        tracker.init(first_frame, roi)
    elif algorithm_type == "KCFè¿½è¸ªå™¨":
        tracker = cv2.TrackerKCF_create()
        tracker.init(first_frame, roi)
    elif algorithm_type == "MOSSEè¿½è¸ªå™¨":
        tracker = cv2.legacy.TrackerMOSSE_create()
        tracker.init(first_frame, roi)
    else:
        return None

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        if algorithm_type in ["CSRTè¿½è¸ªå™¨", "KCFè¿½è¸ªå™¨", "MOSSEè¿½è¸ªå™¨"]:
            success, box = tracker.update(frame)
            if success:
                x, y, w, h = [int(v) for v in box]
                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
            else:
                cv2.putText(frame, "Tracking failed", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

        out.write(frame)

    cap.release()
    out.release()

    return output_path

def main():
    algorithm_options = [
        "CSRTè¿½è¸ªå™¨", 
        "KCFè¿½è¸ªå™¨", 
        "MOSSEè¿½è¸ªå™¨"
    ]

    with gr.Blocks(
        title="è§†é¢‘å¤„ç†ä¸è¿½è¸ªåº”ç”¨",
        css="""html, body, .gradio-container {
            height: 100%;
            margin: 0;
            padding: 0;
            background: linear-gradient(135deg, #FF6347, #FF4500, #FFD700, #9ACD32, #00BFFF, #8A2BE2);
            background-size: 600% 600%;
            animation: gradientAnimation 10s ease infinite;
        }

        @keyframes gradientAnimation {
            0% {
                background-position: 0% 50%;
            }
            50% {
                background-position: 100% 50%;
            }
            100% {
                background-position: 0% 50%;
            }
        }
        """,
    ) as demo:
        gr.Markdown("## ğŸ¯ è§†é¢‘å¤„ç†ä¸è¿½è¸ªåº”ç”¨")
        gr.Markdown("ä¸Šä¼ è§†é¢‘ï¼Œé€‰æ‹©ç®—æ³•ï¼ˆå«ç›®æ ‡è¿½è¸ªï¼‰ï¼Œæ‰“æ ‡åæŸ¥çœ‹è¾“å‡ºç»“æœ")

        with gr.Row():
            video_input = gr.Video(label="ä¸Šä¼ è§†é¢‘", height=480)

        with gr.Row():
            algorithm_type = gr.Dropdown(
                choices=algorithm_options,
                label="é€‰æ‹©ç®—æ³•ç±»å‹",
                value="CSRTè¿½è¸ªå™¨"
            )
            process_btn = gr.Button("å¤„ç†è§†é¢‘")

        with gr.Row():
            video_output = gr.Video(label="å¤„ç†ç»“æœ", height=480)

        def unified_process(video_path, algorithm_type):
            return track_video(video_path, algorithm_type)

        process_btn.click(
            fn=unified_process,
            inputs=[video_input, algorithm_type],
            outputs=video_output
        )

    demo.launch(share=True)


# åŸæœ‰ç°åº¦/è¾¹ç¼˜/æ¨¡ç³Šå¤„ç†å‡½æ•°ä¿ç•™
def process_video(video_path, algorithm_type):
    cap = cv2.VideoCapture(video_path)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps == 0 or fps is None or fps < 1:
        fps = 30
    output_path = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False).name
    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        if algorithm_type == "ç°åº¦è½¬æ¢":
            processed_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            processed_frame = cv2.cvtColor(processed_frame, cv2.COLOR_GRAY2BGR)
        elif algorithm_type == "è¾¹ç¼˜æ£€æµ‹":
            processed_frame = cv2.Canny(frame, 100, 200)
            processed_frame = cv2.cvtColor(processed_frame, cv2.COLOR_GRAY2BGR)
        elif algorithm_type == "é«˜æ–¯æ¨¡ç³Š":
            processed_frame = cv2.GaussianBlur(frame, (15, 15), 0)
        else:
            processed_frame = frame
        out.write(processed_frame)

    cap.release()
    out.release()
    return output_path

if __name__ == "__main__":
    main()
